{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD优化器\n",
    "opt = optim.SGD(model.parameters(), lr = lr) # model是网络模型, lr是学习率\n",
    "# Momentum 动量加速\n",
    "opt_Momentum = optim.SGD(model,parameters(), lr=lr, momentum=0.8) \n",
    "# RMSprop, hyperparameters alpha\n",
    "opt_RMSprop = optim.RMSprop(model.parameters(), lr=lr, alpha=0.9)\n",
    "# Adam, hyperparameters betas\n",
    "opt_Adam = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and use the dataset\n",
    "\n",
    "import torch.utils.data.dataset as Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在应用Dataset抽象类创建子类时，通常需要重写__ inti __ 初始化方法来定义数据内容和标签，重写 __ len __ 方法来返回数据集大小，以及重写 __ getitem __ 方法来得到数据内容和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集大小为： 4\n",
      "(tensor([3., 2.]), tensor([0.]))\n",
      "(tensor([3., 2.]), tensor([0.]))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Create sub\n",
    "class subDataset(Dataset.Dataset):\n",
    "    # Init\n",
    "    def __init__(self, Data, Label):\n",
    "        self.Data = Data\n",
    "        self.Label = Label\n",
    "    # return len\n",
    "    def __len__(self):\n",
    "        return len(self.Data)\n",
    "    # get the data and label\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.Tensor(self.Data[index])\n",
    "        label = torch.Tensor(self.Label[index])\n",
    "        return data, label\n",
    "    \n",
    "# Struct Dataset\n",
    "Data = np.asarray([[3, 2], [1, 4], [7, 2], [3, 1]]) # 将python的list转换为numpy的\n",
    "Label = np.asarray([[0], [0], [1], [1]])\n",
    "\n",
    "sub = subDataset(Data, Label) # 创建数据集对象\n",
    "print('数据集大小为：', sub.__len__())\n",
    "print(sub.__getitem__(0)) # 第0项的数据\n",
    "print(sub[0]) # 等于上一行\n",
    "\n",
    "# if __name__ == 'main':\n",
    "#     sub = subDataset(Data, Label) # 创建数据集对象\n",
    "#     print('数据集大小为：', sub.__len__())\n",
    "#     print(sub.__getitem__(0)) # 第0项的数据\n",
    "#     print(sub[0]) # 等于上一行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户通过自己创建的Dataset对象的子类来构建数据集对象，之后就可以使用该对象来读取数据集的相关数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and use DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data.dataloader as DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在创建Dataloader迭代器对象时，需将将用户构建的数据集对象作为参数。\n",
    "\n",
    "下面代码：对象是sub，num_workers是子进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  tensor([[3., 2.],\n",
      "        [1., 4.]])\n",
      "label:  tensor([[0.],\n",
      "        [0.]])\n",
      "data:  tensor([[7., 2.],\n",
      "        [3., 1.]])\n",
      "label:  tensor([[1.],\n",
      "        [1.]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader.DataLoader(sub, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "for i, item in enumerate(dataloader):\n",
    "    data, label = item\n",
    "    print('data: ', data)\n",
    "    print('label: ', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收录了若干重要的公开数据集，网络模型和常用的图像变换方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision.datasets 数据集下载模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data.dataset as Dataset\n",
    "import torchvision\n",
    "# 全局取消证书验证,数据集更容易被下载成功\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# 分别下载训练集和测试集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=None)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=None)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision.models 预训练模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
