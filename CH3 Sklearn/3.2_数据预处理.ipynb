{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2.1 缺失值补全\n",
    "## 单变量插值法（SimpleInputer）\n",
    "使用参数missing_values指定真实数据中缺失值的标识，使用参数strategy指定插值策略，取值为\"mean\"、\"median\"、\"most_frequent\"或\"constant\"，分别表示使用每列的平均值、中位数、众数或指定某个常数来替换缺失值，该常数使用fill_value参数指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  1  2]\n",
      " [ 6 10  5]\n",
      " [ 7  8 10]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "#定义Imputer对象\n",
    "i=SimpleImputer(missing_values=0,strategy='constant',fill_value=10)# use constant 10 to replace missing value 0\n",
    "i.fit([[0,1,2]]) # fit()函数让Imputer对象适应(拟合)数据，参数为2维数组\n",
    "X = np.array([[0,1,2], [6,0,5], [7,8,0]])# 原始数据,列数应与fit函数参数列数相同\n",
    "X1 = i.transform(X)# 将X中的所有缺失值填补，返回填补后的二维数组 \n",
    "print(X1)\n",
    "print(type(X1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit函数通过设置参数指明了要转换的二维数组的列数，SimpleImputer也提供了fit_transform函数，直接进行拟合数据并对缺省值填补，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  1  2 10]\n",
      " [ 6 10  5 10]\n",
      " [ 7  8 10 10]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "i2 = SimpleImputer(missing_values=0, strategy='constant', fill_value=10)\n",
    "X = np.array([[0,1,2,0], [6,0,5,0], [7,8,0,0]])  # 原始数据,3行4列\n",
    "X2 = i2.fit_transform(X)# 先fit后进行transform操作，返回填补后的二维数组\n",
    "print(X2)\n",
    "print(type(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before [[nan, 1, 3], [0, nan, 2], [4, 3, 1]]\n",
      "after [[2. 1. 3.]\n",
      " [0. 2. 2.]\n",
      " [4. 3. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "i3 = SimpleImputer(missing_values=np.nan,strategy='mean') # mean\n",
    "print(\"before\",[[np.nan,1,3],[0,np.nan,2],[4,3,1]])\n",
    "print(\"after\",i3.fit_transform([[np.nan,1,3],[0,np.nan,2],[4,3,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1  2\n",
      "0     k  x\n",
      "1  a  m   \n",
      "2  b     y\n",
      "3  a  m  x\n",
      "---\n",
      "[['a' 'k' 'x']\n",
      " ['a' 'm' 'x']\n",
      " ['b' 'm' 'y']\n",
      " ['a' 'm' 'x']]\n"
     ]
    }
   ],
   "source": [
    "# Most Freqent\n",
    "i4 = SimpleImputer(missing_values='',strategy='most_frequent')\n",
    "p=pd.DataFrame([['','k','x'],['a','m',''],['b','','y'],['a','m','x']],dtype=\"category\")\n",
    "print(p)\n",
    "print(\"---\")\n",
    "print(i4.fit_transform(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多变量插值（IterativeImputer）\n",
    "\n",
    "多变量插值IterativeImputer类利用各列非缺省值构建函数为每个缺失值进行建模。建模采用迭代循环方式执行，即在每个步骤中，将目标列指定为输出y，将其他列视为输入X，使用一个回归模型对(Ｘ，ｙ)进行拟合，然后使用这个回归模型来预测缺失的ｙ值。IterativeImputer类也是通过参数missing_values指定真实数据中缺失值的标识，通过参数max_iter控制迭代次数，默认值为10。\n",
    "\n",
    "以下代码给出了使用多变量插值方法进行数据插补的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan, 11], [6, nan], [nan, 6], [3, 17]]\n",
      "[[ 4.9999985  11.        ]\n",
      " [ 6.         12.999999  ]\n",
      " [ 2.49999975  6.        ]\n",
      " [ 3.         17.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "imp = IterativeImputer(missing_values=np.nan)\n",
    "imp.fit([[1, 3],[2, 5],[3, 7]])\n",
    "X_test = [[np.nan, 11], [6, np.nan], [np.nan, 6],[3,17]]\n",
    "print(X_test)\n",
    "print(imp.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 数据无量纲化\n",
    "\n",
    "许多机器学习算法中的目标函数是假设所有的特征为零均值且具有相同方差。\n",
    "\n",
    "如果数据某维特征的方差比其他维度的特征大几个数量级，那么这个特征可能会在学习算法中占据**主导**位置，导致模型无法从其他特征中学习到好的分类效果。\n",
    "\n",
    "因此，我们常常需要对数据进行去量纲的操作，提升模型的收敛速度和精度。\n",
    "\n",
    "### (1)最小最大归一化（MinMaxScaler）\n",
    "\n",
    "归一化方法将每列数据缩放到给定的最小值和最大值之间。转换公式为：\n",
    "                   \n",
    "$$X_{scaled}=(X-min⁡( X))\\frac{Max-Min}{max⁡( X)-min⁡( X)}+Min$$\n",
    "\n",
    "其中，Min和Max是指定的最小值和最大值。通常使用MinMaxScaler类进行归一化操作，其中一个重要的参数feature_range用于控制缩放的范围，默认值为(0,1)，类型为tuple. 示例如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -1, 2], [2, 0, 0], [0, 1, -1]]\n",
      "[[0.5        0.         1.        ]\n",
      " [1.         0.5        0.33333333]\n",
      " [0.         1.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train = [[1, -1, 2], [2, 0, 0], [0, 1, -1]]\n",
    "min_max_scalar = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_minmax = min_max_scalar.fit_transform(X_train)\n",
    "print(X_train)\n",
    "print(X_train_minmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）最大绝对值归一化（MaxAbsScaler）\n",
    "\n",
    "最大绝对值归一化与最小最大归一化类似，只不过它将每列数据按最大绝对值进行归一化。转换公式表达为：\n",
    "\n",
    "$$X_{scaled}=\\frac{X}{max⁡( abs (X))}$$\n",
    "\n",
    "因此，每列数据都会映射在[-1,1]范围内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -1, 2], [2, 0, 0], [0, -2, -1]]\n",
      "[[ 0.5 -0.5  1. ]\n",
      " [ 1.   0.   0. ]\n",
      " [ 0.  -1.  -0.5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "X_tr = [[1, -1, 2], [2, 0, 0], [0, -2, -1]]\n",
    "mas = MaxAbsScaler()\n",
    "X_re = mas.fit_transform(X_tr) # 注意先进行fit，后进行transform\n",
    "print(X_tr)\n",
    "print(X_re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3）Z-score标准化（StandardScaler）\n",
    "\n",
    "Z-score标准化是指将每列数转换为服从为均值为0，方差为1的正态分布（即标准正态分布）的数据。设某列原始数据X的均值为μ，标准差为σ，则转换公式为：\n",
    "\n",
    "$$X_{std}=\\frac{X-μ}{σ}$$  \n",
    "\n",
    "Z-score标准化是非常常见的归一化方法，示例如下：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean [2.         0.33333333 0.        ]\n",
      "std [0.81649658 1.24721913 4.3204938 ]\n",
      "X_train_re [[ 0.5 -0.5  1. ]\n",
      " [ 1.   0.   0. ]\n",
      " [ 0.  -1.  -0.5]]\n",
      "X_test_re [[-1.22474487  1.33630621  0.69436507]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "scalar = ss() # 实例化\n",
    "X_train = [[1, -1, 2], [2, 0, 4], [3, 2, -6]]\n",
    "scalar.fit(X_train) # 在训练集上训练，得到均值和方差\n",
    "print('mean', scalar.mean_)  # 查看得到的均值\n",
    "print('std', scalar.scale_)  # 查看得到的方差\n",
    "\n",
    "X_train_re = scalar.transform(X_train)# 在训练集上归一化\n",
    "print('X_train_re', X_re)  # 打印训练集归一化结果\n",
    "X_test_re = scalar.transform([[1, 2, 3]])  # 在测试集上归一化\n",
    "print('X_test_re', X_test_re)  # 打印测试集归一化结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 类别特征编码\n",
    "\n",
    "### （1）标签编码（LabelEncoder） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:  ['beijing', 'shanghai', 'shenzhen']\n",
      "[0 1]\n",
      "['shenzhen', 'shenzhen', 'shanghai']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit([\"beijing\", \"shanghai\", \"beijing\", \"shenzhen\"])\n",
    "print(\"labels: \", list(le.classes_))  # 打印所有的标签集合\n",
    "print(le.transform([\"beijing\", \"shanghai\"]))  # 打印给定标签对应的编码\n",
    "print(list(le.inverse_transform([2, 2, 1])))  # 打印编码对应的原始标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）多标签二值化编码（MultiLabelBinarizer）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coding: [[1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "mlb=MultiLabelBinarizer()\n",
    "Y = [['beijing', 'chengdu'], ['chengdu', 'tianjin'],['chongqing'],['guangzhou'], ['shanghai'], ['shenzhen'], ['tianjin']]\n",
    "\n",
    "mlb.fit(Y) # 训练标签数据\n",
    "\n",
    "print('coding:', mlb.transform([['beijing','shanghai']]))  # 打印新标签编码结果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （3）特征按序编码（OrdinalEncoder） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories:  [array(['female', 'male'], dtype=object), array(['beijing', 'shanghai', 'shenzhen'], dtype=object)]\n",
      "encode:  [[1. 2.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "oe=OrdinalEncoder()\n",
    "X = [['male', 'beijing'], ['female', 'shenzhen'], ['male', 'shanghai']]\n",
    "oe.fit(X) # 进行训练\n",
    "print(\"categories: \", oe.categories_)  # 打印类别\n",
    "# 打印对新数据的编码结果\n",
    "print(\"encode: \", oe.transform([['male','shenzhen'], ['female', 'beijing']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （4）独热编码（OneHotEncoder）\n",
    "其原理类似于多标签二值化编码，只不过独热编码只能用于数据特征的编码，不能用于标签编码。设数据的某列特征有N个可能的取值，则将该列特征变换为长度为N的二进制特征向量，其中只有一个位置上是1，其余位置都是0，这也是与多标签二值化编码不同的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories:  [array(['female', 'male'], dtype=object), array(['beijing', 'shanghai', 'shenzhen'], dtype=object)]\n",
      "encode: [[1. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "X = [['male', 'beijing'], ['female', 'shanghai'], \n",
    "['male', 'shenzhen'], ['female', 'beijing']]\n",
    "\n",
    "ohe.fit(X)\n",
    "\n",
    "print(\"categories: \", ohe.categories_)  # 查看特征取值  \n",
    "print(\"encode:\", ohe.transform([['female','shenzhen']]).toarray()) # 输出特征编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.4 离散化\n",
    "\n",
    "### （1）K-bins离散化（KBinsDiscretizer）\n",
    "K-bins离散化是指将连续数值型特征值排序后通过使用k个等宽的区间分箱后编码，使得原来连续型变量划分为分类变量。\n",
    "\n",
    "KBinsDiscretizer类中包含3个重要的参数，其中n_bins参数表示每维特征的分箱个数，默认为5，会被运用到所有导入的特征上。encode参数表示编码方式，可取值为\"onehot\"、\"ordinal\"、\"onehot-dense\"，默认\"onehot\"。strategy参数表示分箱方式，可取值为\"uniform\"、\"quantile\"、\"kmeans\"，分别表示等宽分箱、等位分箱、按聚类分箱，默认\"quantile\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge: [array([-3., -1.,  2.,  6.]) array([3., 5., 6.]) array([11., 14., 15.])]\n",
      "coding: [[0. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [2. 0. 0.]]\n",
      "coding: [[0. 0. 0.]\n",
      " [0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[-3, 5, 15],[0, 6, 14],[6, 3, 11]])\n",
    "kbd=KBinsDiscretizer(n_bins=[3,2,2],encode='ordinal')\n",
    "kbd.fit(X)\n",
    "print('Edge:', kbd.bin_edges_)  # 显示分箱边界\n",
    "print('coding:', kbd.transform(X))  # 对训练数据的离散结果\n",
    "print('coding:', kbd.transform([[-10,2,0],[-1,5.5,16]]))  # 对新数据的离散结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）二值化（Binarizer） \n",
    "通过设定阈值将连续型数值特征划分得到布尔值（0或1）的过程。\n",
    "\n",
    "在计算机视觉中，针对灰度图像的二值化的作用就是将图像变为黑白图像，以便于进行图像分割、目标提取等操作。\n",
    "\n",
    "Binarizer类提供了参数threshold，用于设置各个维度上的阈值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "X = [[1.,-1.,2.],[2.,0.,0.],[0.,1.,-1.]]\n",
    "binarizer = Binarizer(threshold=1.0).fit(X)\n",
    "# 源代码这里好像错了 源代码：threshold=[1,0,1]\n",
    "print(binarizer.transform(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
